{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# from sktime.classifiers.distance_based import KNeighborsTimeSeriesClassifier\n",
    "from tslearn.neighbors import KNeighborsTimeSeriesClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sktime.utils.load_data import load_from_tsfile_to_dataframe\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(filename=\"1_nn_dtw_results_history.log\", level=logging.INFO)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc_before_knn_dtw(X):\n",
    "    X = X.applymap(np.array)\n",
    "\n",
    "    dimensions_lst = []\n",
    "\n",
    "    for dim in X.columns:\n",
    "        dimensions_lst.append(np.dstack(list(X[dim].values))[0])\n",
    "\n",
    "    dimensions_lst = np.array(dimensions_lst)\n",
    "    X = torch.from_numpy(np.array(dimensions_lst, dtype=np.float64))\n",
    "    X = X.transpose(0, 2)\n",
    "    X = X.transpose(1, 2)\n",
    "    X = F.normalize(X, dim=1)\n",
    "    X = X.float().numpy()\n",
    "    return X\n",
    "\n",
    "\n",
    "def preproc_answers(y):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    y = le.fit_transform(y)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run on all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9953447a943e4c6f947c9f56de985eab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=28), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CharacterTrajectories\n",
      "data has been loaded\n",
      "Error: smth is wrong\n",
      "\n",
      "SpokenArabicDigits\n",
      "data has been loaded\n",
      "Error: smth is wrong\n",
      "\n",
      "PhonemeSpectra\n"
     ]
    }
   ],
   "source": [
    "datasets_directory = \"/root/data/Multivariate_ts/\"\n",
    "datasets_names_lst = os.listdir(datasets_directory)\n",
    "\n",
    "for dataset_name in tqdm(datasets_names_lst[3:]): # start from the 3rd dataset\n",
    "    logging.info(f'{dataset_name}')\n",
    "    print(dataset_name)\n",
    "    \n",
    "    try:\n",
    "        X_train, y_train = load_from_tsfile_to_dataframe(datasets_directory\\\n",
    "                                                         + dataset_name + f'/{dataset_name}_TRAIN.ts')\n",
    "        X_test, y_test = load_from_tsfile_to_dataframe(datasets_directory\\\n",
    "                                                       + dataset_name + f'/{dataset_name}_TEST.ts')\n",
    "        print('data has been loaded')\n",
    "        \n",
    "        X_train = preproc_before_knn_dtw(X_train)\n",
    "        X_test = preproc_before_knn_dtw(X_test)\n",
    "        \n",
    "        y_train = preproc_answers(y_train)\n",
    "        y_test = preproc_answers(y_test)\n",
    "        print('data has been preprocessed')\n",
    "        \n",
    "        knn_dtw = KNeighborsTimeSeriesClassifier(n_neighbors=1, metric='dtw')\n",
    "        knn_dtw.fit(X_train, y_train)\n",
    "\n",
    "        test_predictions = knn_dtw.predict(X_test)\n",
    "        test_accuracy = accuracy_score(test_predictions, y_test)\n",
    "        logging.info(f\"test_accuracy: {test_accuracy}\\n\")\n",
    "        print('test_accuracy:',test_accuracy)\n",
    "        print('\\n')\n",
    "    except:\n",
    "        print('Error: smth is wrong\\n')\n",
    "        logging.info(f\"Error: smth is wrong\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One dataset example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_name = 'InsectWingbeat'\n",
    "# dataset_name = 'ERing'\n",
    "# dataset_name = 'Cricket'\n",
    "dataset_name = 'PenDigits'\n",
    "\n",
    "datasets_directory = \"/root/data/Multivariate_ts/\"\n",
    "\n",
    "X_train, y_train = load_from_tsfile_to_dataframe(datasets_directory + dataset_name + f'/{dataset_name}_TRAIN.ts')\n",
    "X_test, y_test = load_from_tsfile_to_dataframe(datasets_directory + dataset_name + f'/{dataset_name}_TEST.ts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = preproc_before_knn_dtw(X_train)\n",
    "X_test = preproc_before_knn_dtw(X_test)\n",
    "\n",
    "y_train = preproc_answers(y_train)\n",
    "y_test = preproc_answers(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model was fitted\n"
     ]
    }
   ],
   "source": [
    "# knn_dtw = KNeighborsTimeSeriesClassifier(n_neighbors=1, metric='dtw')\n",
    "knn_dtw = KNeighborsTimeSeriesClassifier(n_neighbors=1, metric='dtw')\n",
    "knn_dtw.fit(X_train, y_train)\n",
    "print('model was fitted')\n",
    "\n",
    "# train_predictions = knn_dtw.predict(X_train)\n",
    "# train_accuracy = accuracy_score(train_predictions, y_train)\n",
    "# print('train_accuracy:',round(train_accuracy,5))\n",
    "\n",
    "test_predictions = knn_dtw.predict(X_test)\n",
    "test_accuracy = accuracy_score(test_predictions, y_test)\n",
    "print('test_accuracy:', round(test_accuracy,5))\n",
    "logging.info(f\"{dataset_name}: {round(test_accuracy,5)}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
